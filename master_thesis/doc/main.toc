\contentsline {chapter}{\numberline {1}Introduction}{12}{chapter.1}%
\contentsline {section}{\numberline {1.1}Overview}{12}{section.1.1}%
\contentsline {section}{\numberline {1.2}Thesis and Code}{14}{section.1.2}%
\contentsline {paragraph}{\nonumberline Python Code}{14}{paragraph*.11}%
\contentsline {paragraph}{\nonumberline Target Use Case}{14}{paragraph*.13}%
\contentsline {section}{\numberline {1.3}Thesis Outline}{14}{section.1.3}%
\contentsline {chapter}{\numberline {2}Project Setup}{15}{chapter.2}%
\contentsline {section}{\numberline {2.1}Data}{15}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}News Articles}{15}{subsection.2.1.1}%
\contentsline {paragraph}{\nonumberline Sources}{15}{paragraph*.15}%
\contentsline {paragraph}{\nonumberline Data Description}{16}{paragraph*.17}%
\contentsline {subsection}{\numberline {2.1.2}Company Data}{16}{subsection.2.1.2}%
\contentsline {section}{\numberline {2.2}Spacy}{16}{section.2.2}%
\contentsline {paragraph}{\nonumberline Pipeline Components}{17}{paragraph*.20}%
\contentsline {paragraph}{\nonumberline Custom Component}{18}{paragraph*.22}%
\contentsline {paragraph}{\nonumberline Pipeline Plugins}{18}{paragraph*.24}%
\contentsline {paragraph}{\nonumberline Custom Extensions}{18}{paragraph*.26}%
\contentsline {paragraph}{\nonumberline Modularity and Custom Pipeline}{18}{paragraph*.28}%
\contentsline {subsection}{\numberline {2.2.1}Usage}{19}{subsection.2.2.1}%
\contentsline {paragraph}{\nonumberline Other Python Libraries}{19}{paragraph*.30}%
\contentsline {chapter}{\numberline {3}Text Representation}{20}{chapter.3}%
\contentsline {section}{\numberline {3.1}Overview}{20}{section.3.1}%
\contentsline {section}{\numberline {3.2}Definitions}{20}{section.3.2}%
\contentsline {section}{\numberline {3.3}Traditional Methods}{21}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}One-Hot-Encoding}{21}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Bag-of-Words}{21}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Document Similarities}{22}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}Feature Dimension Reduction}{22}{subsection.3.3.4}%
\contentsline {subsubsection}{\nonumberline Remove Stop Words}{22}{subsubsection*.34}%
\contentsline {subsubsection}{\nonumberline Remove Function Words}{23}{subsubsection*.36}%
\contentsline {subsubsection}{\nonumberline Reduce words to their Lemmas and Stems}{23}{subsubsection*.38}%
\contentsline {subsubsection}{\nonumberline Others}{23}{subsubsection*.40}%
\contentsline {subsection}{\numberline {3.3.5}TF-IDF}{23}{subsection.3.3.5}%
\contentsline {section}{\numberline {3.4}Word Embeddings\footnote {This section was mainly taken from \cite {LfdTalk15}}}{24}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Static Word Vectors}{24}{subsection.3.4.1}%
\contentsline {subsubsection}{\nonumberline Manually crafted features}{25}{subsubsection*.44}%
\contentsline {subsubsection}{\nonumberline Learned features}{26}{subsubsection*.49}%
\contentsline {subsubsection}{\nonumberline The problem with static word embeddings}{27}{subsubsection*.53}%
\contentsline {subsection}{\numberline {3.4.2}Contextual Word Embeddings}{28}{subsection.3.4.2}%
\contentsline {subsubsection}{\nonumberline Transformer Architecture}{29}{subsubsection*.56}%
\contentsline {subsubsection}{\nonumberline Self-Attention}{29}{subsubsection*.59}%
\contentsline {paragraph}{\nonumberline \emph {time flies like an arrow}}{32}{figure.caption.66}%
\contentsline {paragraph}{\nonumberline \emph {fruit flies like a banana}}{33}{paragraph*.68}%
\contentsline {paragraph}{\nonumberline \emph {Different embeddings for same word depending on context}}{33}{paragraph*.71}%
\contentsline {section}{\numberline {3.5}Is a \gls {gen-llm} all you need?}{34}{section.3.5}%
\contentsline {paragraph}{\nonumberline \glspl {gen-llm}}{34}{paragraph*.73}%
\contentsline {paragraph}{\nonumberline \gls {RAG} Systems}{34}{paragraph*.75}%
\contentsline {paragraph}{\nonumberline The Hallucination problem}{34}{paragraph*.77}%
\contentsline {paragraph}{\nonumberline Questions in regard to LLMs}{35}{paragraph*.79}%
\contentsline {chapter}{\numberline {4}\gls {ner} - Named Entity Recognition}{36}{chapter.4}%
\contentsline {section}{\numberline {4.1}Background}{36}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Rule-Based Models}{36}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Machine Learning Models}{36}{subsection.4.1.2}%
\contentsline {subparagraph}{\nonumberline Hidden Markov Models}{37}{subparagraph*.81}%
\contentsline {subparagraph}{\nonumberline Conditional Random Fields}{37}{subparagraph*.84}%
\contentsline {subsection}{\numberline {4.1.3}Deep Learning Models}{38}{subsection.4.1.3}%
\contentsline {paragraph}{\nonumberline Pre-Trained Models}{38}{paragraph*.87}%
\contentsline {paragraph}{\nonumberline \glspl {gen-llm}}{39}{paragraph*.89}%
\contentsline {section}{\numberline {4.2}Code-Implementation}{39}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Implementation of Pre-Trained Model}{39}{subsection.4.2.1}%
\contentsline {subsection}{\numberline {4.2.2}Implementation of Rule-Base Model}{40}{subsection.4.2.2}%
\contentsline {paragraph}{\nonumberline \gls {Regex}}{40}{paragraph*.91}%
\contentsline {paragraph}{\nonumberline Implementation Details}{42}{paragraph*.93}%
\contentsline {paragraph}{\nonumberline Pattern Naming and Multithreading}{44}{paragraph*.95}%
\contentsline {paragraph}{\nonumberline Comparing Rule-Based vs. Pre-Trained vs. \glspl {gen-llm}}{45}{paragraph*.97}%
\contentsline {subsection}{\numberline {4.2.3}Implementation of \gls {gen-llm} model}{46}{subsection.4.2.3}%
\contentsline {subsection}{\numberline {4.2.4}Information Extraction Pipeline}{48}{subsection.4.2.4}%
\contentsline {chapter}{\numberline {5}\gls {coref_resolution_definition}}{50}{chapter.5}%
\contentsline {section}{\numberline {5.1}Background}{50}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Definitions}{50}{subsection.5.1.1}%
\contentsline {subsection}{\numberline {5.1.2}Methods}{51}{subsection.5.1.2}%
\contentsline {subparagraph}{\nonumberline Mention Detection}{51}{subparagraph*.104}%
\contentsline {subparagraph}{\nonumberline Rule Based Methods}{51}{subparagraph*.106}%
\contentsline {subparagraph}{\nonumberline Feature Based Methods}{51}{subparagraph*.108}%
\contentsline {subparagraph}{\nonumberline Neural Network Based Methods}{51}{subparagraph*.110}%
\contentsline {section}{\numberline {5.2}Models}{52}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Pre-Trained Models}{52}{subsection.5.2.1}%
\contentsline {paragraph}{\nonumberline Research}{52}{paragraph*.112}%
\contentsline {subparagraph}{\nonumberline e2e: End-to-end Neural \gls {coref_resolution_definition}}{52}{subparagraph*.114}%
\contentsline {subparagraph}{\nonumberline c2f: Higher-order \gls {coref_resolution_definition} with Coarse-to-fine Inference}{54}{subparagraph*.118}%
\contentsline {subparagraph}{\nonumberline BERT for \gls {coref_resolution_definition}}{54}{subparagraph*.120}%
\contentsline {subparagraph}{\nonumberline s2e: \gls {coref_resolution_definition} without \gls {span} Representations}{54}{subparagraph*.122}%
\contentsline {paragraph}{\nonumberline Available Models}{55}{paragraph*.126}%
\contentsline {subparagraph}{\nonumberline AllenNLP}{55}{subparagraph*.128}%
\contentsline {subparagraph}{\nonumberline F-COREF}{55}{subparagraph*.130}%
\contentsline {subparagraph}{\nonumberline Coreferee}{55}{subparagraph*.132}%
\contentsline {subparagraph}{\nonumberline Crosslingual-Coreference}{55}{subparagraph*.134}%
\contentsline {paragraph}{\nonumberline Evaluated Pre-Trained Models}{56}{paragraph*.136}%
\contentsline {subsection}{\numberline {5.2.2}\gls {gen-llm} Models}{56}{subsection.5.2.2}%
\contentsline {paragraph}{\nonumberline Pre-Trained AND Generative}{56}{paragraph*.138}%
\contentsline {paragraph}{\nonumberline Models used}{57}{paragraph*.140}%
\contentsline {section}{\numberline {5.3}Code Implementation}{57}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Implementation of Pre-Trained Model}{57}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}Implementation of \gls {gen-llm} Model}{60}{subsection.5.3.2}%
\contentsline {paragraph}{\nonumberline Data Model}{60}{paragraph*.142}%
\contentsline {subparagraph}{\nonumberline \gls {prompt}}{62}{subparagraph*.144}%
\contentsline {subparagraph}{\nonumberline Response Format}{63}{subparagraph*.146}%
\contentsline {subparagraph}{\nonumberline Processing the LLM Response}{64}{subparagraph*.148}%
\contentsline {subparagraph}{\nonumberline Collecting Entities}{65}{subparagraph*.150}%
\contentsline {paragraph}{\nonumberline Topic Sentences}{67}{paragraph*.152}%
\contentsline {subsection}{\numberline {5.3.3}Comparing Pre-Trained vs. \gls {gen-llm} approach}{67}{subsection.5.3.3}%
\contentsline {subsection}{\numberline {5.3.4}Information Extraction Pipeline}{68}{subsection.5.3.4}%
\contentsline {chapter}{\numberline {6}Topic Modelling}{69}{chapter.6}%
\contentsline {section}{\numberline {6.1}Information Extraction Types}{69}{section.6.1}%
\contentsline {section}{\numberline {6.2}Traditional Topic Modelling}{70}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}\gls {nmf}}{71}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}\gls {svd}}{72}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}\gls {lda}}{72}{subsection.6.2.3}%
\contentsline {section}{\numberline {6.3}Embedding-based Topic Modelling}{73}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Pre-Trained Topic Models}{73}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}BERTopic}{74}{subsection.6.3.2}%
\contentsline {paragraph}{\nonumberline Sentence Transformer Embeddings}{76}{paragraph*.161}%
\contentsline {paragraph}{\nonumberline Word Vectors}{77}{paragraph*.164}%
\contentsline {paragraph}{\nonumberline Performance}{77}{paragraph*.167}%
\contentsline {section}{\numberline {6.4}Topic Modelling with \gls {gen-llm}s}{78}{section.6.4}%
\contentsline {paragraph}{\nonumberline Data Model}{78}{paragraph*.169}%
\contentsline {paragraph}{\nonumberline LangChain Code}{80}{paragraph*.171}%
\contentsline {paragraph}{\nonumberline Aggregation of Sentences}{81}{paragraph*.173}%
\contentsline {paragraph}{\nonumberline The Token Limit Problem}{81}{paragraph*.175}%
\contentsline {subsection}{\numberline {6.4.1}Comparing Pre-Trained vs. \gls {gen-llm} approach}{83}{subsection.6.4.1}%
\contentsline {section}{\numberline {6.5}Information Extraction Pipeline}{83}{section.6.5}%
\contentsline {chapter}{\numberline {7}Knowledge Graph\footnote {Part of the Python code for this section was adopted from \cite {projdigi}}}{85}{chapter.7}%
\contentsline {section}{\numberline {7.1}Introduction}{85}{section.7.1}%
\contentsline {section}{\numberline {7.2}Knowledge Graph Creation}{85}{section.7.2}%
\contentsline {paragraph}{\nonumberline Ontology}{86}{paragraph*.179}%
\contentsline {paragraph}{\nonumberline Graph Preparation}{88}{paragraph*.181}%
\contentsline {paragraph}{\nonumberline Data Preparation}{89}{paragraph*.183}%
\contentsline {paragraph}{\nonumberline Company Symbol and \gls {isin}}{90}{paragraph*.185}%
\contentsline {paragraph}{\nonumberline Data Loading}{90}{paragraph*.187}%
\contentsline {section}{\numberline {7.3}External Data}{94}{section.7.3}%
\contentsline {paragraph}{\nonumberline SPARQL}{95}{paragraph*.192}%
\contentsline {section}{\numberline {7.4}Information Retrieval}{97}{section.7.4}%
\contentsline {paragraph}{\nonumberline \gls {cypher} Queries}{97}{paragraph*.196}%
\contentsline {section}{\numberline {7.5}Sentence Embeddings and Sentiment}{99}{section.7.5}%
\contentsline {section}{\numberline {7.6}\gls {graph-bot}}{101}{section.7.6}%
\contentsline {paragraph}{\nonumberline \gls {graph-bot} vs. \gls {llm} Chatbot}{104}{paragraph*.205}%
\contentsline {paragraph}{\nonumberline Production Use Case}{105}{paragraph*.207}%
\contentsline {paragraph}{\nonumberline Knowledge Graph as RAG}{105}{paragraph*.209}%
\contentsline {chapter}{\numberline {8}Conclusion}{106}{chapter.8}%
\contentsline {chapter}{\numberline {A}Explanation of \textbf {MAIN.ipynb} file}{108}{appendix.A}%
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
