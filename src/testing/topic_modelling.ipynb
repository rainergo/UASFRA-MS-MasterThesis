{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stop_words_en\n",
    "from spacy.lang.de.stop_words import STOP_WORDS as stop_words_de\n",
    "\n",
    "from utils.text_cleaner import sub_fancy_quot_marks"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ],
   "id": "c674d1d44ad32e95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sentences = [\"it was the best of times particularly\", \n",
    "             \"it was the worst of times\", \n",
    "             \"it was the age of wisdom\", \n",
    "             \"it was the age of foolishness\",\n",
    "             \"it is an orange\",\n",
    "             \"it is an apple\",]\n",
    "\n",
    "tokenized_sentences = [[t for t in sentence.split()] for sentence in sentences]\n",
    "tokenized_sentences"
   ],
   "id": "116639cf7fada6d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vocabulary = set([w for s in tokenized_sentences for w in s])\n",
    "vocabulary"
   ],
   "id": "3171b52a2ee52894",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "words = list(set(vocabulary))\n",
    "words"
   ],
   "id": "d3816c470c22a7ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "[[w, i] for i,w in enumerate(vocabulary)]",
   "id": "303123538a660369",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_data = pd.DataFrame(sentences, columns=['sentence'])\n",
    "df_data"
   ],
   "id": "2f24223fb1e8cf1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### MultiLabelBinarizer",
   "id": "433deb1f49a20219"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Note: The MultiLabelBinarizer only shows IF a word is in the vocab, but not how often !!!\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit([vocabulary])\n",
    "class_word_map = [cl for cl in mlb.classes_]\n",
    "data = mlb.transform(tokenized_sentences)\n",
    "df_mlb = pd.DataFrame(data, columns=class_word_map)\n",
    "df_mlb"
   ],
   "id": "a371aeab1fce333b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### CountVectorizer",
   "id": "a218d1c1a485dafa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Note: CountVectorizer (contrary to MLB above) not only checks if a given word appears in the text, but also how often the word appears.\n",
    "cv = CountVectorizer(analyzer='word',\n",
    "                     binary=False,\n",
    "                     decode_error='strict',\n",
    "                     ngram_range=(1, 1), \n",
    "                     stop_words='english')\n",
    "cv.fit(sentences)\n",
    "tcv = cv.transform(sentences)\n",
    "df_cv = pd.DataFrame(tcv.toarray(), columns=cv.get_feature_names_out())\n",
    "df_cv"
   ],
   "id": "433f9fe4833870f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Note cosine_similarity based on the number of times a word appears in a sentence\n",
    "labels = [f'sent_{i +1}' for i in range(len(sentences))]\n",
    "df_sim = pd.DataFrame(cosine_similarity(tcv, tcv), columns=labels, index=labels)\n",
    "df_sim"
   ],
   "id": "5f9cadaa64544aac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TF-IDF",
   "id": "9c00ffd4f95c7ca4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tid = tfidf.fit_transform(sentences)\n",
    "df_tfid = pd.DataFrame(tid.toarray(), columns=tfidf.get_feature_names_out())\n",
    "df_tfid"
   ],
   "id": "6e3962d3f2908cf6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "frame = tid.toarray()\n",
    "print(type(frame))\n",
    "frame.shape"
   ],
   "id": "e2b11f6cef892e97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Note: Get most common words in all texts\n",
    "tfidf_most_common_words_all = list()\n",
    "for col in df_tfid:\n",
    "    tfidf_most_common_words_all.append((col, sum(df_tfid[col])))\n",
    "sorted(tfidf_most_common_words_all, key=lambda x: x[1], reverse=True)[:5]"
   ],
   "id": "24f0baea29dde37f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Note: Get most common in each text\n",
    "tfidf_most_common_words_in_text = list()\n",
    "for ind, row in df_tfid.iterrows():\n",
    "    print(row.tolist())\n",
    "    # print(sorted(list(zip(df_tfid.columns, row.tolist())), key=lambda x: x[1], reverse=True))\n",
    "    print('----------')\n",
    "    # tfidf_most_common_words_in_text.append((f'sent_{ind}', row))\n",
    "\n",
    "print(tfidf_most_common_words_in_text)\n",
    "#     tfidf_most_common_words_in_text.append((col, sum(df_tfid[col])))\n",
    "# sorted(tfidf_most_common_words_in_text, key=lambda x: x[1], reverse=True)[:5]"
   ],
   "id": "ac289778ff5cd2af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_tfid.columns.size",
   "id": "d5f362ae385fcd63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### TF-IDF: Reducing feature dimensions with:",
   "id": "15c2c66f93b1ddfa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### stopwords",
   "id": "6cce2c436f096436"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Note: Make choice\n",
    "# Note: stop-words contain starnge chars that first must be cleaned\n",
    "\n",
    "stop_words_de:list = sub_fancy_quot_marks(text=' '.join(list(stop_words_de))).replace(\"'\", \"\").split()\n",
    "stop_words_en:list = sub_fancy_quot_marks(text=' '.join(list(stop_words_en))).replace(\"'\", \"\").split()\n",
    "stop_words:list = list(set(stop_words_en + stop_words_de))"
   ],
   "id": "6f37376c166453ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### minimum and maximum percentage of appearance before a word remains in the text",
   "id": "f5e77173daf0c24f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Note: A float input for parameter \"min_df\" means: minimum pct of documents the given word must appear in. Otherwise it is removed.\n",
    "min_pct_of_docs_word_must_appear_in:float = 0.00    # higher number -> less common words remain in text\n",
    "max_pct_of_docs_word_can_appear_in:float = 0.30    # higher number -> more common words remain in text\n",
    "tfidf_sw = TfidfVectorizer(min_df=min_pct_of_docs_word_must_appear_in, max_df=max_pct_of_docs_word_can_appear_in)\n",
    "tid_sw = tfidf_sw.fit_transform(sentences)\n",
    "df_tfid_sw = pd.DataFrame(tid_sw.toarray(), columns=tfidf_sw.get_feature_names_out())\n",
    "df_tfid_sw"
   ],
   "id": "c254ade31d6165f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_sim = pd.DataFrame(cosine_similarity(tid_sw, tid_sw), columns=labels, index=labels)\n",
    "df_sim"
   ],
   "id": "f3d496ec87b191ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### linguistic features",
   "id": "19d33b5a5c620b6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "nlp_en = spacy.load('en_core_web_trf')\n",
    "nlp_de = spacy.load('de_dep_news_trf')\n",
    "\n",
    "nouns_adjectives_verbs = [\"NOUN\", \"PROPN\", \"ADJ\", \"ADV\", \"VERB\"]\n",
    "for i, row in df_data.iterrows():\n",
    "    doc = nlp_en(str(row[\"sentence\"]))\n",
    "    df_data.at[i, \"lemmas\"] = \" \".join([token.lemma_ for token in doc])\n",
    "    df_data.at[i, \"not_a_verb\"] = \" \".join([token.lemma_ for token in doc if token.pos_ in nouns_adjectives_verbs])\n",
    "\n",
    "df_data"
   ],
   "id": "76d6354254e5f3d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Note: Use lemmatized words here. But cold also be other features such as \n",
    "tfidf_lf = TfidfVectorizer()\n",
    "# use = 'lemmas'\n",
    "use = 'not_a_verb'\n",
    "tid_lf = tfidf_lf.fit_transform(df_data[use].map(str))\n",
    "df_tfid_lf = pd.DataFrame(tid_lf.toarray(), columns=tfidf_lf.get_feature_names_out())\n",
    "df_tfid_lf"
   ],
   "id": "2c88e8d1951a3a65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9e26e224cae2e7c9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
